{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9dYn4x2s+DYTKxwR7RFb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajendra-theDataEngineer004627/BigDataAssignments/blob/Assignment11/Assignment12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyRO9ecU-ukY"
      },
      "outputs": [],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "X9lj_grK_yZ7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "jIRloHHH_4fb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "V91ktK6e_6AL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "HgzeDwYc_mCQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "M4GzGUoUAH4W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"<app_name>\")\n",
        " .getOrCreate())"
      ],
      "metadata": {
        "id": "pgzOWk8_--Uw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to doanload data files from the google drive\n",
        "import gdown\n",
        "def downloadfiles_fromFolder() :\n",
        "    url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"   # can also be used input()\n",
        "    if url.split(\"/\")[-1]== \"?usp=sharing\":\n",
        "       url = url.replace(\"?usp=sharing\",\"\")\n",
        "    gdown.download_folder(url, output=\"/content\")\n",
        "\n",
        "downloadfiles_fromFolder()"
      ],
      "metadata": {
        "id": "Zm1ANzlU_CQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}